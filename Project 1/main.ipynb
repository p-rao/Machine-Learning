{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the code to calculate the logistic regression for the WDBC dataset.\n",
    "# The equations are mentioned below along with a number which correspond to \n",
    "# their equivalent explanation in the report. The hyperparamters have been\n",
    "# explicitly stated and the results of the experiment of accuracy, precision,\n",
    "# recall and F1 score have been explained in the report as well.\n",
    "\n",
    "# The standardization technique which was the best fit for this data set is\n",
    "# uncommented. The other methods have been commented and were used as part of the\n",
    "# analysis process. Tuning of the hyperparameters was done on a trial and error\n",
    "# basis, plugging in the values as deemed necessary.\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to load data from CSV and map 0s and 1s\n",
    "def load_data():\n",
    "    # Load data from CSV\n",
    "    data_frame = pandas.read_csv('wdbc.csv', header=None)\n",
    "    # Drop Patient ID column\n",
    "    data_frame.drop(data_frame.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    # Map M to 1 and B to 0\n",
    "    data_frame = data_frame.replace('M', value=1)\n",
    "    data_frame = data_frame.replace('B', value=0)\n",
    "    return data_frame\n",
    "\n",
    "# Function to calculate sigmoid (Equation 2)\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + numpy.exp(-1 * z))\n",
    "\n",
    "\n",
    "# Function to calculate loss (Equation 3)\n",
    "def loss(h, y, m):\n",
    "    return (-1 / m) * numpy.sum(\n",
    "        numpy.dot(y.transpose(), numpy.log(h)) + numpy.dot((1 - y.transpose()), numpy.log(1 - h)))\n",
    "\n",
    "\n",
    "# Function to calculate delta theta (Equation 6)\n",
    "def update_weight(y, a, x, m):\n",
    "    return (-1 / m) * (numpy.dot((y - a).transpose(), x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Fetch data frame from the csv file\n",
    "    data_frame = load_data()\n",
    "    # Split data frame to 80-10-10 ratio for train, validation and test respectively\n",
    "    train, validate, test = numpy.split(data_frame.sample(frac=1),\n",
    "                                        [int(.8 * len(data_frame)), int(.9 * len(data_frame))])\n",
    "\n",
    "    # Normalize the training data - using min max scaler\n",
    "    min_max_scalar = preprocessing.MinMaxScaler()\n",
    "    # min_max_scalar = preprocessing.StandardScaler()\n",
    "    x_scaled_train = min_max_scalar.fit_transform(train.values)\n",
    "    df_train = pandas.DataFrame(x_scaled_train)\n",
    "    \n",
    "    # Normalize the validation data - using min max scaler\n",
    "    x_scaled_validate = min_max_scalar.fit_transform(validate.values)\n",
    "    df_validate = pandas.DataFrame(x_scaled_validate)\n",
    "    \n",
    "    # Normalize the testing data - using min max scaler\n",
    "    x_scaled_test = min_max_scalar.fit_transform(test.values)\n",
    "    df_test = pandas.DataFrame(x_scaled_test)\n",
    "\n",
    "    # Split to feature vectors and target vectors for each of the datasets\n",
    "    X_train = df_train[df_train.columns[1:]]\n",
    "    Y_train = df_train[df_train.columns[:1]]\n",
    "    X_test = df_test[df_test.columns[1:]]\n",
    "    Y_test = df_test[df_test.columns[:1]]\n",
    "    X_validate = df_validate[df_validate.columns[1:]]\n",
    "    Y_validate = df_validate[df_validate.columns[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias\n",
    "bias = 0\n",
    "# Weights\n",
    "theta = numpy.zeros((30, 1))\n",
    "# Lists to track loss values for each epoch for both training and validation data\n",
    "loss_train_tracker = []\n",
    "loss_validation_tracker = []\n",
    "# Hyperparameter 1 : Epoch\n",
    "epoch_val = 500\n",
    "for epoch in range(0, epoch_val):\n",
    "    # Training data forward pass\n",
    "    # hypothesis function (Equation 1)\n",
    "    predicted_train_vector = numpy.dot(X_train, theta) + bias\n",
    "    a_train_vector = sigmoid(predicted_train_vector)\n",
    "    m1 = X_train[1].shape[0]\n",
    "    values_for_loss_function_train = loss(a_train_vector, Y_train, m1)\n",
    "    loss_value_train = values_for_loss_function_train\n",
    "    loss_train_tracker.append(loss_value_train)\n",
    "\n",
    "    # Validation data forward pass\n",
    "    predicted_validate_vector = numpy.dot(X_validate, theta) + bias\n",
    "    a_validate_vector = sigmoid(predicted_validate_vector)\n",
    "    m2 = X_validate[1].shape[0]\n",
    "    values_for_loss_function_validate = loss(a_validate_vector, Y_validate, m2)\n",
    "    loss_value_validate = values_for_loss_function_validate\n",
    "    loss_validation_tracker.append(loss_value_validate)\n",
    "    \n",
    "    # Training data backward pass\n",
    "    # Hyperparamter 2 : Learning Rate\n",
    "    learning_rate = 0.5\n",
    "    for i in range(0, 30):\n",
    "        # Update each weight (Equation 4)\n",
    "        theta[i] -= (\n",
    "                learning_rate * update_weight(Y_train, a_train_vector, X_train[i + 1], X_train[i + 1].shape[0]))\n",
    "    # Update bias (Equation 5 and 7)\n",
    "    bias -= (learning_rate * (-1 / m1 * numpy.sum(Y_train - a_train_vector)))\n",
    "    bias = bias.__float__()\n",
    "# Plot the graphs\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss versus Epoch, LR = 0.5')\n",
    "plt.plot(range(epoch_val), loss_train_tracker, 'r', range(epoch_val), loss_validation_tracker, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data \n",
    "predicted_test_vector = numpy.dot(X_test, theta) + bias\n",
    "a_test_vector = numpy.array(sigmoid(predicted_test_vector))\n",
    "predicted_test_result = []\n",
    "FP = 0 # False Positive\n",
    "TP = 0 # True Positive\n",
    "FN = 0 # False Negative\n",
    "TN = 0 # True Negative\n",
    "y_test_data = numpy.array(Y_test)\n",
    "for i in range(0, len(a_test_vector)):\n",
    "    # Classify output of the sigmoid as 1 or 0\n",
    "    if a_test_vector[i] >= 0.5:\n",
    "        predicted_test_result.append(1)\n",
    "    else:\n",
    "        predicted_test_result.append(0)\n",
    "    if y_test_data[i] == predicted_test_result[i]:\n",
    "        if predicted_test_result[i] == 1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    elif y_test_data[i] == 1 and predicted_test_result[i] == 0:\n",
    "        FN += 1\n",
    "    else:\n",
    "        FP += 1\n",
    "# Accuracy calculation\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# Precision calculation\n",
    "precision = TP / (TP + FP)\n",
    "# Recall calculation\n",
    "recall = TP / (TP + FN)\n",
    "# F1 Score calculation\n",
    "f1_score = 2*((precision * recall)/(precision + recall)) # 2*TP / (2*TP + FP + FN)\n",
    "print(f\"Accuracy : {accuracy}\\nPrecision : {precision}\\nRecall : {recall}\\nF1 Score : {f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
